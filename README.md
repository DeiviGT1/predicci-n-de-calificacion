# üöó Descripci√≥n del Proyecto üöó

Este proyecto se centra en el procesamiento y an√°lisis de datos relacionados con despachos de art√≠culos y su maestro, con el objetivo de preparar los datos para su uso en modelos de machine learning. Incluye scripts para la preparaci√≥n de datos, entrenamiento de modelos y generaci√≥n de predicciones.

## üìÅ Archivos del Proyecto üìÅ

### 1. `data_preparation.py` üõ†Ô∏è

Este script se encarga de preparar los datos relacionados con los despachos de art√≠culos y su maestro. Contiene funciones para consultas SQL, limpieza y transformaci√≥n de datos en DataFrames de Pandas, y combinaci√≥n de datos de diferentes fuentes.

### 2. `data_processing.py` üîÑ

El script `data_processing.py` se encarga de preparar los datos para su uso en modelos de machine learning. Contiene funciones para filtrar datos, dividirlos en conjuntos de entrenamiento y prueba, y crear pipelines de procesamiento de datos para su posterior utilizaci√≥n en el entrenamiento de modelos.

### 3. `model.py` ü§ñ

Este script se centra en el entrenamiento de modelos de machine learning utilizando diferentes clasificadores. Se encarga de cargar los datos preparados, entrenar los modelos y generar predicciones para un conjunto espec√≠fico de datos, con el fin de facilitar la toma de decisiones basadas en el an√°lisis de los resultados obtenidos.

## üöÄ Ejecuci√≥n del Proyecto üöÄ

Para ejecutar el proyecto, sigue estos pasos:

1. Aseg√∫rate de tener instaladas todas las dependencias necesarias. Puedes instalarlas utilizando el siguiente comando:
  pip install -r requirements.txt

2. Ejecuta los scripts en el siguiente orden:

   - `data_preparation.py`
   - `data_processing.py`
   - `model.py`

Aseg√∫rate de ajustar los par√°metros necesarios en el archivo `model.py` antes de ejecutarlo.

## üì¶ Dependencias üì¶

El proyecto utiliza las siguientes dependencias:

- `scikit-learn`: Para el preprocesamiento de datos y entrenamiento de modelos de machine learning.
- `pandas`: Para la manipulaci√≥n y an√°lisis de datos.
- `numpy`: Para operaciones num√©ricas.
- `sqlalchemy`: Para la conexi√≥n y consultas a bases de datos SQL.
- `openpyxl`: Para leer archivos Excel.
- `matplotlib`: Para visualizaci√≥n de datos.

Aseg√∫rate de tener estas dependencias instaladas antes de ejecutar el proyecto.

## üß† Modelos Seleccionados üß†

Durante el desarrollo de este proyecto, se han seleccionado tres modelos de machine learning para abordar distintos aspectos del problema:

1. **Modelo de Redes Neuronales**:
   - Las redes neuronales son conocidas por su capacidad para aprender patrones complejos en datos, lo que las hace adecuadas para una amplia gama de problemas de clasificaci√≥n y regresi√≥n.
   - Pueden manejar conjuntos de datos grandes y de alta dimensionalidad, adapt√°ndose bien a problemas con una gran cantidad de caracter√≠sticas.
   - En este caso, el modelo de redes neuronales puede ser √∫til si el problema es intr√≠nsecamente complejo y no puede ser abordado eficazmente por modelos m√°s simples como los √°rboles de decisi√≥n o KNN.

2. **√Årboles de Decisi√≥n**:
   - Los √°rboles de decisi√≥n son modelos simples de entender e interpretar, lo que los hace √∫tiles para tareas de clasificaci√≥n y regresi√≥n.
   - Son robustos frente a datos ruidosos y f√°ciles de visualizar, lo que facilita la comprensi√≥n de c√≥mo se toman las decisiones.
   - Los √°rboles de decisi√≥n son excelentes candidatos cuando se requiere una explicabilidad del modelo y se cuenta con caracter√≠sticas f√°cilmente interpretables.

3. **K-Nearest Neighbors (KNN)**:
   - KNN es un algoritmo simple y no param√©trico utilizado tanto para clasificaci√≥n como para regresi√≥n.
   - Su enfoque se basa en la suposici√≥n de que las instancias similares tienden a estar cerca en el espacio de caracter√≠sticas.
   - KNN puede ser particularmente √∫til cuando la estructura subyacente de los datos es compleja y no lineal.

La elecci√≥n de estos tres modelos proporciona una diversidad de enfoques que pueden complementarse entre s√≠ para abordar diferentes aspectos y desaf√≠os del problema. En conjunto, esta combinaci√≥n de modelos ofrece flexibilidad y capacidad para abordar una variedad de escenarios en el procesamiento y an√°lisis de datos relacionados con despachos de art√≠culos y su maestro.


## üìä Evaluaci√≥n de Resultados: Matriz de Confusi√≥n üìä

Para evaluar el rendimiento de los modelos de machine learning seleccionados en este proyecto, se emple√≥ la t√©cnica de la matriz de confusi√≥n. La matriz de confusi√≥n es una herramienta fundamental en la evaluaci√≥n de modelos de clasificaci√≥n, ya que proporciona una visi√≥n detallada de c√≥mo el modelo est√° clasificando las instancias en diferentes clases.

La matriz de confusi√≥n organiza las predicciones del modelo en una tabla, donde las filas representan las clases reales y las columnas representan las clases predichas por el modelo. Las celdas de la matriz muestran el n√∫mero de instancias clasificadas correctamente (verdaderos positivos y verdaderos negativos) y incorrectamente (falsos positivos y falsos negativos) para cada clase.

Analizar la matriz de confusi√≥n permite identificar patrones de error del modelo, como la tendencia a confundir ciertas clases entre s√≠, y proporciona m√©tricas de evaluaci√≥n adicionales como precisi√≥n, exhaustividad y F1-score.

La interpretaci√≥n adecuada de la matriz de confusi√≥n es crucial para comprender el rendimiento del modelo y tomar decisiones informadas sobre posibles ajustes o mejoras en el proceso de entrenamiento.

En este proyecto, la matriz de confusi√≥n se utiliz√≥ como una herramienta integral para evaluar y comparar el rendimiento de los modelos de redes neuronales, √°rboles de decisi√≥n y K-Nearest Neighbors en la tarea de clasificaci√≥n de despachos de art√≠culos y su maestro.

## ‚úçÔ∏è Autor ‚úçÔ∏è

Este proyecto fue desarrollado por [David Gonzalez](https://github.com/DeiviGT1).

